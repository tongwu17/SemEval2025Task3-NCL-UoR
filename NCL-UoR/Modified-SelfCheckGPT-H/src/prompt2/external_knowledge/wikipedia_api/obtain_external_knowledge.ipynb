{"cells":[{"cell_type":"markdown","id":"fe6dd2a7-261b-44a5-a276-b545ccce827e","metadata":{"id":"fe6dd2a7-261b-44a5-a276-b545ccce827e"},"source":["# Obtain External Knowledge"]},{"cell_type":"markdown","id":"27bff76e-1f50-42e0-afeb-c283e870ae25","metadata":{"id":"27bff76e-1f50-42e0-afeb-c283e870ae25"},"source":["1. Extractor Keywords\n","\n","2. Acquire External Knowledge:\n","  1. Use Baidu Translate API to translate all extracted key phrases into English as a fallback mechanism for retrieval.\n","  2. Retrieval Rollback Mechanism:\n","First, use the key phrases in the target language to search via the Wikipedia API.\n","    1. If the search fails, use the translated English phrases for retrieval.\n","Note: During retrieval, there might be errors due to Traditional Chinese redirects. These need to be cleared, and results in Traditional Chinese should be forcefully converted.\n","  3. Extract the first 200 characters from the search results."]},{"cell_type":"code","execution_count":null,"id":"517c6d3d-5358-4551-aef1-aacb4e974afd","metadata":{"id":"517c6d3d-5358-4551-aef1-aacb4e974afd"},"outputs":[],"source":["import pandas as pd\n","import time\n","from deep_translator import GoogleTranslator\n","from requests.adapters import HTTPAdapter\n","from urllib3.util.retry import Retry\n","import requests\n","import random\n","import json\n","from hashlib import md5\n","from tqdm import tqdm\n","import spacy\n","import os"]},{"cell_type":"markdown","id":"fc987eaf-a570-4f75-a7bf-9d6b502cdcc2","metadata":{"id":"fc987eaf-a570-4f75-a7bf-9d6b502cdcc2"},"source":["## Translate the Keywords - Baidu API"]},{"cell_type":"code","execution_count":null,"id":"e467319c-2771-4b94-968a-3007de321eb2","metadata":{"id":"e467319c-2771-4b94-968a-3007de321eb2"},"outputs":[],"source":["# Baidu Translate API setting\n","appid = ''\n","appkey = ''\n","endpoint = 'http://api.fanyi.baidu.com'\n","path = '/api/trans/vip/translate'\n","url = endpoint + path\n","\n","from_lang = 'auto'\n","to_lang = 'en'\n","\n","def make_md5(s, encoding='utf-8'):\n","    return md5(s.encode(encoding)).hexdigest()\n","\n","def baidu_api(query, from_lang='auto', to_lang='en'):\n","    salt = random.randint(32768, 65536)\n","    sign = make_md5(appid + query + str(salt) + appkey)\n","    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n","    payload = {\n","        'appid': appid,\n","        'q': query,\n","        'from': from_lang,\n","        'to': to_lang,\n","        'salt': salt,\n","        'sign': sign\n","    }\n","    try:\n","        r = requests.post(url, params=payload, headers=headers)\n","        result = r.json()\n","        if 'trans_result' in result:\n","            return [item['dst'] for item in result['trans_result']]\n","        else:\n","            print(f\"Translate failed: {result}\")\n","            return [query]\n","    except Exception as e:\n","        print(f\"Request failed: {e}\")\n","        return [query]\n","\n","def translate_keyphrases(keywords):\n","    if not keywords:\n","        return []\n","    batch_query = '\\n'.join(keywords)\n","    return baidu_api(batch_query)\n"]},{"cell_type":"markdown","id":"b1c2cab0-1aad-4f17-8f89-3fa5e7a1331d","metadata":{"id":"b1c2cab0-1aad-4f17-8f89-3fa5e7a1331d"},"source":["### Apply on the Dataset"]},{"cell_type":"code","execution_count":null,"id":"996975e8-dcb1-452a-b01d-803147d068a9","metadata":{"scrolled":true,"id":"996975e8-dcb1-452a-b01d-803147d068a9"},"outputs":[],"source":["input_dir = '../data/detect_val/extract_m2/'\n","output_dir = '../data/detect_val/m2_translated_keywords/'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","def process_jsonl(input_path, output_path):\n","    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n","        for line in tqdm(infile, desc=f\"Processing {os.path.basename(input_path)}\"):\n","            data = json.loads(line)\n","            if 'keywords' in data:\n","                try:\n","                    data['keywords_en'] = translate_keyphrases(data['keywords'])\n","                except Exception as e:\n","                    print(f\"Translate failed (file: {input_path}, row: {line}): {e}\")\n","                    data['keywords_en'] = []\n","            json.dump(data, outfile, ensure_ascii=False)\n","            outfile.write('\\n')\n","\n","\n","file_list = [f for f in os.listdir(input_dir) if f.endswith('.jsonl')]\n","for filename in tqdm(file_list, desc=\"Processing Files\"):\n","    input_path = os.path.join(input_dir, filename)\n","    output_path = os.path.join(output_dir, filename)\n","    process_jsonl(input_path, output_path)"]},{"cell_type":"markdown","id":"261b6377-8bba-4aa0-8bde-859e9c2f75da","metadata":{"id":"261b6377-8bba-4aa0-8bde-859e9c2f75da"},"source":["## Obtain the External Knowledge"]},{"cell_type":"code","execution_count":null,"id":"16424a82-75c2-41fc-bdb4-09a506a603fd","metadata":{"id":"16424a82-75c2-41fc-bdb4-09a506a603fd"},"outputs":[],"source":["lang_map = {\n","    'ar': 'ar',\n","    'de': 'de',\n","    'en': 'en',\n","    'es': 'es',\n","    'fi': 'fi',\n","    'fr': 'fr',\n","    'hi': 'hi',\n","    'it': 'it',\n","    'sv': 'sv',\n","    'zh': 'zh',\n","    'ca': 'ca',\n","    'fa': 'fa',\n","    'cs': 'cs',\n","    'eu': 'eu'\n","}\n","\n","proxies = {\n","    \"http\": \"http://127.0.0.1:10809\",\n","    \"https\": \"http://127.0.0.1:10809\",\n","    \"socks5\": \"socks5://127.0.0.1:10808\"\n","}\n","\n","# A function to clean up the Chinese redirect prompt text\n","def clean_redirect_text(text):\n","    return \"\\n\".join([line for line in text.split(\"\\n\") if \"重定向\" not in line and \"轉換系統\" not in line])\n","\n","\n","# Wikipedia API searching function\n","def fetch_wikipedia_summary(query, lang, proxies, timeout=30):\n","    url = f\"https://{lang}.wikipedia.org/w/api.php\"\n","    params = {\n","        \"action\": \"query\",\n","        \"format\": \"json\",\n","        \"titles\": query,\n","        \"prop\": \"extracts\",\n","        \"exintro\": True,\n","        \"explaintext\": True,\n","    }\n","    if lang == 'zh':\n","        params[\"variant\"] = \"zh-cn\"\n","    try:\n","        response = requests.get(url, params=params, proxies=proxies, timeout=timeout)\n","        response.raise_for_status()\n","        data = response.json()\n","        pages = data.get(\"query\", {}).get(\"pages\", {})\n","        for _, page in pages.items():\n","            if \"extract\" in page:\n","                summary = page[\"extract\"]\n","                return clean_redirect_text(summary)\n","        return \"\"\n","    except Exception as e:\n","        return f\"request fail: {e}\"\n","\n","\n","def fetch_summaries_for_keyphrases(phrases, lang):\n","    summaries = []\n","    for phrase in phrases:\n","        summary = fetch_wikipedia_summary(phrase, lang, proxies)\n","        if summary:\n","            summaries.append(summary[:200])\n","        else:\n","            summaries.append(\"\")\n","        time.sleep(1)\n","    return summaries"]},{"cell_type":"code","execution_count":null,"id":"98ef6ef6-dcf6-4de8-9e73-1ac3d0e71780","metadata":{"id":"98ef6ef6-dcf6-4de8-9e73-1ac3d0e71780"},"outputs":[],"source":["def process_jsonl(input_path, output_path):\n","    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n","        for line in tqdm(infile, desc=f\"Processing {os.path.basename(input_path)}\"):\n","            data = json.loads(line)\n","            lang = data.get('lang', 'en')\n","            keyphrases = data.get('keywords', [])\n","            keyphrases_en = data.get('keywords_en', [])\n","\n","            summaries = fetch_summaries_for_keyphrases(keyphrases, lang)\n","\n","            if all(s == \"\" for s in summaries):\n","                summaries = fetch_summaries_for_keyphrases(keyphrases_en, 'en')\n","\n","            data['wikipedia_context'] = \" \".join(summaries)\n","\n","            json.dump(data, outfile, ensure_ascii=False)\n","            outfile.write('\\n')"]},{"cell_type":"code","execution_count":null,"id":"590cc9c6-c700-4ada-b620-5d01f7a4afec","metadata":{"id":"590cc9c6-c700-4ada-b620-5d01f7a4afec"},"outputs":[],"source":["input_dir = '../data/detect_val/m2_translated_keywords/'\n","output_dir = '../data/detect_val/exknowledge_m2/'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","for filename in os.listdir(input_dir):\n","    if filename.endswith('.jsonl'):\n","        input_path = os.path.join(input_dir, filename)\n","        output_path = os.path.join(output_dir, filename)\n","        process_jsonl(input_path, output_path)"]},{"cell_type":"code","execution_count":null,"id":"06bfd4cd-44be-4b8d-b4c2-f5609f5e97b4","metadata":{"id":"06bfd4cd-44be-4b8d-b4c2-f5609f5e97b4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.20"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}